#!/bin/env python
#
# glint_backup is a stand alone utility for creating incremental backups of glance
# repositories. for more information, see:
#
#               https://github.com/hep-gc/glint/wiki/glint_backup
#

import hashlib
import logging
import json
import os
from subprocess import Popen, PIPE
import sys
import time

from keystoneclient.v2_0 import client as keystone_api
import glanceclient as glance_api
from glintargparse import GlintArgumentParser

# Set environment, determine if master or slave, and call the appropriate function.
def main (argv):
    # Set the system command path. 
    os.environ['PATH'] = '/usr/local/bin:/usr/bin:/bin:/usr/local/sbin:/usr/sbin:/sbin'

    gap = GlintArgumentParser()
    gap.init_restore_arg_parser()
    args = gap.parser.parse_args()
    print "args are %s"%args
    # Set the configuration file path.
    if args.cfgfile is not None:
        print "set config file to %s"%args.cfgfile[0]
        config_file = args.cfgfile[0]
    else:
        config_file = '/usr/local/etc/glint/glint_backup.conf'

    # Read JSON configuration file.
    #   confile=open('/usr/local/etc/glint_backup.conf')
    confile=open(config_file)
    config = json.load(confile)
    confile.close()

    # Establish a log file.
    global logger
    logger = logging.getLogger('glint_backup')
    handler = logging.FileHandler(config['glint_backup_logfile'])
    formatter = logging.Formatter('%(asctime)s %(levelname)s %(message)s')
    handler.setFormatter(formatter)
    logger.addHandler(handler) 
    logger.setLevel(logging.INFO)

    # Ensure we are not running as root.
    uid = os.getuid()
    if uid == 0:
        logger.error('Error: glint_backup must not be run as root; terminating.')
        return 1

    # Ensure only one glint_backup is running at one time.
    p = Popen(['ps', '--no-headers', '-fC', 'glint_backup'], stdout=PIPE, stderr=PIPE)
    stdout, stderr = p.communicate()
    
    if stderr != '' or len(stdout.split()) > 1:
        logger.error('Error: There is more than one glint_backup running. This one is terminating.')
        return 1

    logger.info('Starting.')

    # Authenticate and authorize with keystone.
    p = Popen(['hiera', '-c', config['glint_backup_hiera_config'], config['glint_backup_admin_pw_key']], stdout=PIPE, stderr=PIPE)
    pw, stder = p.communicate()
    print "Retreived PW for rd on rat of %s"%pw
    try:
        keystone = keystone_api.Client(auth_url=config['glint_backup_auth_URL'],
            tenant_name=config['glint_backup_admin_tenant'],
            username=config['glint_backup_admin_user'],
            password=pw[:-1])
    except:
        logger.error('Error: unable to connect to keystone at "%s"; terminating.'%(config['glint_backup_auth_URL']))
        return 1

    # Establish glance connectivity.
    try:
        glance_endpoint = keystone.service_catalog.url_for(service_type='image',endpoint_type='publicURL')
        glance = glance_api.Client('2',glance_endpoint,token=keystone.auth_token)
    except:
        logger.error('Error: unable to connect to glance at "%s"; terminating.'%(glance_endpoint))
        return 1
    print "Now for the hard work"
    
    #check that user specified a version number and ensure it less that versions available
    # Determine previous backup directory (possibly none).
    try:
        version_count = len(os.listdir(config['glint_backup_dir']))
    except:
        logger.error('Error: unable to retrieve the count of current backup versions. Is the backup directory ("%s") mounted?'%(config['glint_backup_dir']))
        return 1
    print "showing version count to be %s version is %s int type version is %s"%(version_count,args.version[0],int(args.version[0]))
    
    if version_count == 0:
        print "No previous backups detected"
        logger.error("There are no backup version to restore from")
        return 1
    if version_count < int(args.version[0]):
        print "Version %s does not exist yet ;) current version is %s"%(int(args.version[0]),version_count)
        logger.error("This version %s does not exist yet ;) current max version is %s"%(int(args.version[0]),version_count) )
        return 1
        
    #once version number is identified
    #get all meta-data from the backup-repo
    #so for each tenant get meta-data of each image
    restore_dir = '%s/%04.0f'%(config['glint_backup_dir'],int(args.version[0]))
    if not os.path.exists(restore_dir):
        logger.error('Previous backup directory "%s" does not exist.'%(restore_dir))
        return 1
    print "The restore directory is %s"%restore_dir
    
    #for each meta data 
    #check if image is the same as in glance - checksum compare

    #if checksum is different or if images does not exist,
    #then remove old image and replace with new one

    #done

# get_checksum: Return the checksum from an image's metadata list.
def get_checksum (metadata):
    global logger
    logger.debug('get_checksum input metadata=%s'%(metadata))
    for i in range(0, len(metadata), 2):
        if metadata[i] == 'checksum':
            logger.debug('get_checksum returning "%s"'%(metadata[i+1]))
            return metadata[i+1]

    logger.debug('get_checksum returning empty string.')
    return ''

# get_version_hash: Return a unique hash string for the backup version.
def get_version_hash (tenants, tenant_xref, images, image_xref):
    hash = []
    for tenant in tenants:
        if tenant_xref[tenant.name] == '__deleted__':
            continue

        hash.append(tenant.name)
        hash.append(tenant.id)

        for image in images[tenant.name]:
            if image_xref[image.id] == '__deleted__':
                continue

            hash.append(image_xref[image.id])

    return hashlib.md5(str(hash)).hexdigest()

# md5sum: Return the image checksum for the specified file.
def md5sum(filename, blocksize=65536):
    hash = hashlib.md5()
    with open(filename, "r+b") as fd:
        for block in iter(lambda: fd.read(blocksize), ""):
            hash.update(block)
    return hash.hexdigest()

# set_checksum: update the checksum within an image's metadata list.
def set_checksum (metadata, new_checksum):
    global logger
    logger.debug('set_checksum input metadata=%s, new_checksum=%s.'%(metadata, new_checksum))
    for i in range(0, len(metadata), 2):
        if metadata[i] == 'checksum':
            logger.debug('set_checksum success.')
            metadata[i+1] = new_checksum
            return metadata[i+1]

    logger.debug('set_checksum failed.')
    return ''

# Entry.
if __name__ == "__main__":
    main(sys.argv)
